{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the template file for creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipeline/sensor_training_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipeline/sensor_training_pipeline.py\n",
    "import os\n",
    "from func_components import load_raw_data\n",
    "from func_components import split_data\n",
    "from jinja2 import Template\n",
    "import kfp\n",
    "from kfp.components import func_to_container_op\n",
    "from kfp.dsl.types import Dict\n",
    "from kfp.dsl.types import GCPProjectID\n",
    "from kfp.dsl.types import GCPRegion\n",
    "from kfp.dsl.types import GCSPath\n",
    "from kfp.dsl.types import String\n",
    "from kfp.gcp import use_gcp_secret\n",
    "\n",
    "# Defaults and environment settings\n",
    "BASE_IMAGE = os.getenv('BASE_IMAGE')\n",
    "TRAINER_IMAGE = os.getenv('TRAINER_IMAGE')\n",
    "RUNTIME_VERSION = os.getenv('RUNTIME_VERSION')\n",
    "PYTHON_VERSION = os.getenv('PYTHON_VERSION')\n",
    "COMPONENT_URL_SEARCH_PREFIX = os.getenv('COMPONENT_URL_SEARCH_PREFIX')\n",
    "USE_KFP_SA = os.getenv('USE_KFP_SA')\n",
    "\n",
    "# Create component factories\n",
    "component_store = kfp.components.ComponentStore(\n",
    "    local_search_paths=None, url_search_prefixes=[COMPONENT_URL_SEARCH_PREFIX])\n",
    "\n",
    "# Create all the component ops\n",
    "caip_train_op = component_store.load_component('ml_engine/train')\n",
    "retrieve_raw_data_op = func_to_container_op(\n",
    "    load_raw_data, base_image=BASE_IMAGE)\n",
    "split_preprocess_data_op = func_to_container_op(\n",
    "    split_data, base_image=BASE_IMAGE)\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "@kfp.dsl.pipeline(\n",
    "    name='Bearing Sensor Data Training',\n",
    "    description='The pipeline for training and deploying an anomaly detector based on an autoencoder')\n",
    "\n",
    "def pipeline_run(project_id,\n",
    "                 region,\n",
    "                 source_bucket_name, \n",
    "                 prefix,\n",
    "                 dest_bucket_name,\n",
    "                 dest_file_name,\n",
    "                 dataset_location='US'):\n",
    "    \n",
    "    # Read in the raw sensor data from the public dataset and load in the project bucket\n",
    "    raw_data = retrieve_raw_data_op(source_bucket_name,\n",
    "                                    prefix,\n",
    "                                    dest_bucket_name,\n",
    "                                    dest_file_name)\n",
    "    \n",
    "    # Preprocess and split the raw data by time\n",
    "    split_data = split_preprocess_data_op(raw_data.outputs['dest_bucket_name'],\n",
    "                                          raw_data.outputs['dest_file_name'],\n",
    "                                          '2004-02-15 12:52:39',\n",
    "                                          True)\n",
    "    \n",
    "    # Set up the training args\n",
    "    train_args = [\"--bucket\", split_data.outputs['bucket_name'],\n",
    "                  \"--train_file\", split_data.outputs['train_dest_file'],\n",
    "                  \"--test_file\", split_data.outputs['test_dest_file'],\n",
    "                  \"--epochs\", 100,\n",
    "                  \"--batch_size\", 10]\n",
    "    \n",
    "    # Train the model on AI Platform\n",
    "    train_model = caip_train_op(project_id,\n",
    "                                region=region,\n",
    "                                master_image_uri=TRAINER_IMAGE,\n",
    "                                args=train_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "ENDPOINT = '542a643864f1d5b3-dot-us-central2.pipelines.googleusercontent.com'\n",
    "ARTIFACT_STORE_URI = 'gs://rrusson-kubeflow-test'\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the base image and load it into gcr.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='rrusson_kubeflow_base'\n",
    "TAG='v1'\n",
    "BASE_IMAGE='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THIS IF THE IMAGE EXISTS!\n",
    "!gcloud builds submit --timeout 15m --tag $BASE_IMAGE base_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training image from the base image and load it into the gcr.io (maybe just have one image?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='rrusson_kubeflow_tf2_trainer'\n",
    "TAG='v1'\n",
    "TRAINER_IMAGE='gcr.io/{}/{}:{}'.format(PROJECT_ID, IMAGE_NAME, TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN THIS IF THE IMAGE EXISTS!\n",
    "!gcloud builds submit --timeout 15m --tag $TRAINER_IMAGE train_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: USE_KFP_SA=False\n",
      "env: BASE_IMAGE=gcr.io/mwpmltr/rrusson_kubeflow_base:v1\n",
      "env: TRAINER_IMAGE=gcr.io/mwpmltr/rrusson_kubeflow_tf2_trainer:v1\n",
      "env: COMPONENT_URL_SEARCH_PREFIX=https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/\n",
      "env: RUNTIME_VERSION=1.15\n",
      "env: PYTHON_VERSION=3.7\n"
     ]
    }
   ],
   "source": [
    "USE_KFP_SA = False\n",
    "\n",
    "COMPONENT_URL_SEARCH_PREFIX = 'https://raw.githubusercontent.com/kubeflow/pipelines/0.2.5/components/gcp/'\n",
    "RUNTIME_VERSION = '1.15'\n",
    "PYTHON_VERSION = '3.7'\n",
    "\n",
    "%env USE_KFP_SA={USE_KFP_SA}\n",
    "%env BASE_IMAGE={BASE_IMAGE}\n",
    "%env TRAINER_IMAGE={TRAINER_IMAGE}\n",
    "%env COMPONENT_URL_SEARCH_PREFIX={COMPONENT_URL_SEARCH_PREFIX}\n",
    "%env RUNTIME_VERSION={RUNTIME_VERSION}\n",
    "%env PYTHON_VERSION={PYTHON_VERSION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dsl-compile --py pipeline/sensor_training_pipeline.py --output sensor_training_pipeline.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Pipeline in AI Platform Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 1176a828-f9b2-4fac-af76-4dd7c67d8415 has been submitted\n",
      "\n",
      "Pipeline Details\n",
      "------------------\n",
      "ID           1176a828-f9b2-4fac-af76-4dd7c67d8415\n",
      "Name         bearing_sensor_anomaly\n",
      "Description\n",
      "Uploaded at  2020-12-03T02:10:36+00:00\n",
      "+--------------------+-----------------+\n",
      "| Parameter Name     | Default Value   |\n",
      "+====================+=================+\n",
      "| project_id         |                 |\n",
      "+--------------------+-----------------+\n",
      "| region             |                 |\n",
      "+--------------------+-----------------+\n",
      "| source_bucket_name |                 |\n",
      "+--------------------+-----------------+\n",
      "| prefix             |                 |\n",
      "+--------------------+-----------------+\n",
      "| dest_bucket_name   |                 |\n",
      "+--------------------+-----------------+\n",
      "| dest_file_name     |                 |\n",
      "+--------------------+-----------------+\n",
      "| dataset_location   | US              |\n",
      "+--------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_NAME='bearing_sensor_anomaly'\n",
    "\n",
    "!kfp --endpoint $ENDPOINT pipeline upload \\\n",
    "-p $PIPELINE_NAME \\\n",
    "sensor_training_pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| Pipeline ID                          | Name                                            | Uploaded at               |\n",
      "+======================================+=================================================+===========================+\n",
      "| 1176a828-f9b2-4fac-af76-4dd7c67d8415 | bearing_sensor_anomaly                          | 2020-12-03T02:10:36+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| 2b75dd48-dce3-4eee-ba58-9935aed42077 | [Tutorial] DSL - Control structures             | 2020-12-03T02:02:19+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| 2c9947e6-24c0-492e-99ec-9ae4353b3378 | [Tutorial] Data passing in python components    | 2020-12-03T02:02:18+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| a5f9bc01-dbf9-443e-8290-7ec50fb21019 | [Demo] TFX - Iris classification pipeline       | 2020-12-03T02:02:17+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| 9147f5d5-de76-4636-925c-dd572c569290 | [Demo] TFX - Taxi tip prediction model trainer  | 2020-12-03T02:02:16+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n",
      "| 7cc5a03d-832d-4600-9b51-149f3849323b | [Demo] XGBoost - Training with confusion matrix | 2020-12-03T02:02:15+00:00 |\n",
      "+--------------------------------------+-------------------------------------------------+---------------------------+\n"
     ]
    }
   ],
   "source": [
    "!kfp --endpoint $ENDPOINT pipeline list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_ID='1176a828-f9b2-4fac-af76-4dd7c67d8415'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'Load_Raw_Data'\n",
    "RUN_ID = 'Run_001'\n",
    "SOURCE_BUCKET_NAME = 'amazing-public-data'\n",
    "PREFIX = 'bearing_sensor_data/bearing_sensor_data/'\n",
    "DEST_BUCKET_NAME = 'rrusson-kubeflow-test'\n",
    "DEST_FILE_NAME = 'raw_data_v3.csv'\n",
    "\n",
    "GCS_STAGING_PATH = '{}/staging'.format(ARTIFACT_STORE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating experiment Load_Raw_Data.\n",
      "(400)\n",
      "Reason: Bad Request\n",
      "HTTP response headers: HTTPHeaderDict({'Content-Length': '1451', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Wed, 02 Dec 2020 20:32:44 GMT', 'Vary': 'Origin', 'X-Content-Type-Options': 'nosniff', 'X-Frame-Options': 'SAMEORIGIN', 'X-Powered-By': 'Express', 'X-Xss-Protection': '0', 'Set-Cookie': 'S=cloud_datalab_tunnel=AqcMy91jG0arcx5ykiYV9xfrGNdeG2HH39HsK7cZiag; Path=/; Max-Age=3600'})\n",
      "HTTP response body: \n",
      "<!DOCTYPE html>\n",
      "<html lang=en>\n",
      "  <meta charset=utf-8>\n",
      "  <meta name=viewport content=\"initial-scale=1, minimum-scale=1, width=device-width\">\n",
      "  <title>Error 400 (Bad Request)!!1</title>\n",
      "  <style>\n",
      "    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/logos/errorpage/error_logo-150x54-2x.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n",
      "  </style>\n",
      "  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n",
      "  <p><b>400.</b> <ins>That’s an error.</ins>\n",
      "  <p>  <ins>That’s all we know.</ins>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!kfp --endpoint $ENDPOINT run submit \\\n",
    "-e $EXPERIMENT_NAME \\\n",
    "-r $RUN_ID \\\n",
    "-p $PIPELINE_ID \\\n",
    "project_id=$PROJECT_ID \\\n",
    "gcs_root=$GCS_STAGING_PATH \\\n",
    "region=$REGION \\\n",
    "source_bucket_name=$SOURCE_BUCKET_NAME \\\n",
    "prefix=$PREFIX \\\n",
    "dest_bucket_name=$DEST_BUCKET_NAME \\\n",
    "DEST_FILE_NAME=$DEST_FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mwpmltr'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
